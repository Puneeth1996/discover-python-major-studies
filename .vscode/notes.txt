

Starting on 31 Aug 2020

readme1.md


16Oct 2020

10 Linear Algrebra Series


20Oct 2020
1pm
10.6 - Distance of a point from a PlaneHyperplane, Half-Spaces


1.15pm
11.1 - Introduction to Probability and Statistics



26 Oct 2020
9.45am 

Chapter 12: Probability and Statistics
12.1	Introduction to Probability and Statistics
Datasets with well separable classes do not require ML methods to be applied, but classes that are well mixed cannot be separated easily;
The data points that lie in the mixed region cannot be clearly stated to belong to a certain class; instead we can have probability values of the data point belonging to each class;
Histograms, PDF, CDF, mean, variance, etc come under probability and statistics
Random Variable: can take multiple values in a random manner
	Ex: Dice with 6 sides: Roll a fair dice: the 6 outcomes of the dice are equally likely
	r.v. X = {1, 2, 3, 4, 5, 6}
	Coin toss: r.v. X = {H, T}
	Dice roll: Probability of X = 1 is 1/6
	Probability of X = even is {2,3,4}/{1,2,3,4,5,6} = 3/6 = ½
			= prob(x=2) + prob(x=4) + prob(x=6)
	Height of a randomly picked student: Y = [120 to 190 cm]
	Discrete random variable: a value from a set of values
	Continuous random variable: a value from a range of values
Outlier: Y: Height of students: 
	Let: Y = {122.2, 146.4, 132.5, …, 12.26, 156.23, 92.6}
Outliers: 92.6 and 12.26: may have occurred due to input error or data collection error or may be a genuine value but does not indicate general trend of the population




12.2	Population and Sample
Population example: Set of heights of all people in the world;
Task: estimate the average height of a human;
	Mean = (1/n) sum(h)
Collecting all the population height data is not possible; we will take a random sample (subset of the population) 




12.3	Gaussian/Normal Distribution and its PDF (Probability Density Function)
	Bell shaped curve: Gaussian distribution Probability density function curve;
	X: continuous random variable;
	Real world variables mostly follow Gaussian distribution; Height, Weight, Length 
We learn distributions to understand the underlying statistics or trends of the population
If X behaves as a Gaussian distribution: Given mean and standard variance:
	We can estimate the values of the population; by plotting the PDF
 
The red curve is standard normal distribution
Parameters of Gaussian distribution: Mean and variance:
X ~ N (0,1) (mean 0 and variance 1)
	PDF(X = x) = (1/sqrt(2π) σ) exp(-(x-µ)2/2σ2)
	As x moves from mean, the pdf reduces;
	The PDF of a Normal distribution is symmetric;



	
12.4	CDF (Cumulative Distribution Function) of Gaussian/Normal distribution
	 
	N(µ,2σ2);
	As variance decreases the plot gets converted to a step function;
 
Standard deviation plot: 68 – 95 – 99.7 rule


12.5	Symmetric distribution, Skewness and Kurtosis
	One of the applications of these stats is to understand the distribution;
If the PDF has a mirror image of the curve of the either sides of the mean, then the distribution is symmetric over mean; as in above std dev plot;
F(x0 – h) = F(x0 + h): function symmetric over x0 

Skewness: around the mean the distribution is not symmetric; one of the sides has a longer tail; can be said to be a measure of asymmetry;
 
Sample Skewness:
 
 
Kurtosis:
Excess kurtosis: kurtosis – 3
 
 
Kurtosis of Gaussian random variable =3;
Through excess kurtosis we compare distributions with Gaussian random distribution
	Kurtosis is a measure of tailedness; it is not a measure of peakedness;
	This will give us an idea of outliers in the distribution; Smaller the better



12.6	Standard normal variate (Z) and standardization
	Z ~ N(0,1), mean = 0 and variance = 1
	Let X ~ N(µ,σ2); this can be converted to Z by:
Mean centering and scaling (X – mean) / std dev; To help understand the disb.



12.7	Kernel density estimation
	 
	Computing PDF from Histograms: using KDE;
	A Gaussian Kernel is plotted centered at each observation (of the histogram);
	Variance of this Kernel (bell curve) is called band width;
At every point in the range of the Gaussian Kernels we will add all PDF values to get a combined PDF; bandwidth selection is done by experts;



11.15am


12.8	Sampling distribution & Central Limit theorem
	Let X be a not necessarily Gaussian distribution of a population (say incomes)
	Pick m random Samples independently of size n each  S1, S2, S3, …., Sm
	 For all Samples: compute means, x1m, x2m, x3m, ……
	These sample means will have a distribution: Sampling distribution of sample-mean
	Central Limit Theorem: If X (original population), X: finite mean and variance
Sampling distribution of sample means will be a Gaussian distribution with 		mean = population mean and variance = population variance/n as n increases
It is generally observed that if n is around 30 and m = 1000, we can observe a Gaussian distribution;






12.9	Q-Q plot: How to test if a random variable is normally distributed or not?
Quantile – Quantile plot: Graphical way of determining similarity between two distributions
	X: a new distribution: Task: to understand whether X is Gaussian
1.	Sort X values and compute percentiles;
2.	Y ~ N(0,1): take some k observations and sort + compute percentiles
3.	Plot: X percentile values on Y axis and Y percentile values on x axis
If the plot is approximately a straight line then the distributions are similar;
 
Code: stats.probplot(X, dist = ‘norm’, plot = pylab)
If number of observations is small it is hard to interpret QQ plot;
 
Plot where distributions are different;




12.10	How distributions are used?
	Probability is useful for data analysis;
Ex: Imagine your task is to order T shirts for all employees at your company. Let sizes be S, M, L and XL. Say we have 100k employees who have different size requirements; 
Q) How many XL T shirts should be ordered?
	Collect data for all 100k employees
	Let us have a relationship between heights and T shirt size; Domain knowledge;
	Collect heights from 500 random employees; Compute mean and std dev
	At gate of entry we can do this;
	From domain knowledge, let heights ~N(mean, variance)
We can extend the distribution of heights from 500 employees to 100k employees; We made many assumptions here; these may work in natural features
Q) Salaries: If salaries are Gaussian distributed, we can estimate how many employees make a salary > 100k $;	
So distributions give us a theoretical model of a random variable; This will help us understand the properties of the random variable;



4.20pm

12.11	Chebyshev’s inequality
If we don’t know the distribution and mean is finite and standard deviation is non-zero and finite;
Task: to find the percentage of values of lie within a range;
Salaries of individuals (millions of values); distribution is unknown, but mean and std dev are known;
P(|x - µ| >= kσ) <= 1/k2






12.12	Discrete and Continuous Uniform distributions
	PDF for continuous and PMF for discrete random variables;
	Roll a dice: uniform distribution; each observation is equally probable;
	Discrete Uniform: 
Parameters (a,b,n=b-a+1)
		Pmf = 1/n
		Mean = (a+b) /2 = Median
		Variance = ((b-a+1)2-1)/12
		Skewness = 0
	Continuous Uniform:
		 Parameter: a,b
		PDF: 1/(b-a)
		Mean: (a+b)/2 = Median
Variance = (b-a)2/12


29 Oct 2020
3.30pm


12.13	How to randomly sample data points (Uniform Distribution)
	Using random functions in python;
	We can use a threshold value to generate a random number of random numbers;
	Probability of picking any value is equally probable;



12.14	Bernoulli and Binomial Distribution
	Bernoulli: discrete: Coin toss:{H, T}, P = {0.5, 0.5}; parameter p
	Binomial: X ~ Bernoulli and Y = n times X; parameters: n, p
	An event with n trials with success probability p in each trial and p = 0 or 1
12.15	Log Normal Distribution
	X is log normal if natural logarithm of x is normally distributed;
	  
In user reviews: most of comments are of small length and some of comments have large length of words;
We can employ QQ plot to check similarity of log of distribution to normal distribution;
12.16	Power law distribution
	 
	Green area is 80% values;
	In bottom 20% of values you can find 80% of mass;
When a distribution follows a power law then the distribution is called Pareto distribution; 
Parameters: scale and shape
  
Applications: allocation of wealth in population, sizes of human settlements; 
  
We can also use a QQ plot against Pareto plot;



4pm




12.17	Box cox transform
	Power transform:
	In Machine Learning we assume generally that a feature follows a Gaussian distribution;
	Can we convert Pareto into Gaussian?
	Pareto: X: x1, x2, …., xn	&	Gaussian Y: y1, y2, ….., yn
	Box-cox(x) = λ
	yi = {(xiλ – 1) / λ if λ!=0 and lg(xi) if λ = 0}
	If λ = 0, then the power law distribution is actually a log normal;
	scipy.stats.boxcox()
	Box-cox does not work always. Use QQ-plot to check its results.



























